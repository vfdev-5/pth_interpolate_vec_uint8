Description:
- 20230315-011856-pr
Torch version: 2.1.0a0+git0c58e8a
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 


- 20230313-134520-nightly
Torch version: 2.1.0a0+git5309c44
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 



[---------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------]
                                                                 |  Pillow (9.0.0.post1)  |  torch (2.1.0a0+git0c58e8a) PR  |  torch (2.1.0a0+git5309c44) nightly
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |    38.406 (+-0.471)    |         58.253 (+-0.302)        |          132.536 (+-1.491)         
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         39.468 (+-0.221)        |          110.609 (+-0.746)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |   127.636 (+-1.211)    |        159.757 (+-1.868)        |          292.207 (+-2.027)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        147.364 (+-2.295)        |          276.796 (+-1.953)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |   178.366 (+-2.812)    |        217.410 (+-1.897)        |          416.424 (+-3.683)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        215.276 (+-1.935)        |          414.386 (+-1.848)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |   113.301 (+-1.156)    |        133.986 (+-1.980)        |          441.302 (+-2.747)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         59.195 (+-0.193)        |          364.247 (+-3.346)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |   282.669 (+-2.615)    |        329.728 (+-1.901)        |          691.615 (+-4.512)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        240.732 (+-2.510)        |          583.074 (+-12.854)        
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |   185.815 (+-1.811)    |        206.980 (+-3.308)        |          783.053 (+-4.576)         
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         77.955 (+-0.201)        |          649.771 (+-4.198)         
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |   408.567 (+-1.865)    |        450.529 (+-4.808)        |         1100.548 (+-11.212)        
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        312.496 (+-1.352)        |          906.638 (+-2.984)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |                        |         54.538 (+-1.127)        |           54.386 (+-0.221)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         36.886 (+-0.371)        |           33.479 (+-0.176)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |                        |        148.943 (+-1.214)        |          140.232 (+-1.119)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        136.185 (+-1.979)        |          125.583 (+-1.206)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |                        |        202.034 (+-3.903)        |          185.176 (+-1.279)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        199.681 (+-1.463)        |          183.222 (+-1.245)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |                        |        126.776 (+-1.195)        |          132.561 (+-1.274)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         58.631 (+-0.239)        |           54.603 (+-0.258)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |                        |        290.313 (+-3.392)        |          307.923 (+-2.517)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        217.523 (+-1.335)        |          200.009 (+-1.370)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |                        |        197.762 (+-1.537)        |          207.900 (+-2.445)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         76.021 (+-0.187)        |           71.540 (+-0.259)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |                        |        426.076 (+-3.907)        |          451.936 (+-2.840)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        277.296 (+-1.204)        |          254.801 (+-1.640)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |    38.405 (+-0.586)    |        131.122 (+-1.181)        |          132.604 (+-0.965)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |        113.545 (+-0.848)        |          111.033 (+-0.882)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |   127.347 (+-0.999)    |        299.807 (+-1.560)        |          317.431 (+-4.656)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        288.243 (+-4.318)        |          310.711 (+-4.103)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |   177.883 (+-1.496)    |        434.057 (+-2.109)        |          461.125 (+-7.713)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        432.833 (+-2.877)        |          474.333 (+-8.597)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |   114.094 (+-2.521)    |        438.827 (+-2.615)        |          442.099 (+-3.117)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        368.503 (+-2.069)        |          363.988 (+-2.167)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |   280.878 (+-2.108)    |        674.189 (+-3.539)        |          724.077 (+-4.803)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        602.004 (+-2.700)        |          619.099 (+-4.879)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |   185.771 (+-1.377)    |        942.816 (+-18.742)       |          787.789 (+-5.200)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        653.101 (+-2.212)        |          647.919 (+-3.986)         
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |   407.705 (+-2.374)    |       1083.039 (+-64.094)       |         1132.723 (+-11.433)        
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        930.625 (+-3.470)        |          937.306 (+-4.873)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |                        |         73.030 (+-0.233)        |           73.960 (+-0.207)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |         55.680 (+-0.235)        |           53.132 (+-0.290)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |                        |        257.009 (+-1.415)        |          276.411 (+-7.745)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        243.870 (+-1.704)        |          266.253 (+-3.807)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |                        |        407.975 (+-3.948)        |          451.076 (+-5.440)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        404.848 (+-3.173)        |          441.376 (+-10.967)        
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |                        |        194.561 (+-1.198)        |          201.109 (+-1.703)         
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        126.803 (+-0.778)        |          123.209 (+-1.041)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |                        |        447.155 (+-1.609)        |          481.717 (+-5.655)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        375.078 (+-1.839)        |          392.546 (+-3.717)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |                        |        320.159 (+-1.580)        |          333.681 (+-1.986)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        347.918 (+-42.190)       |          197.557 (+-1.263)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |                        |        788.206 (+-7.208)        |          692.533 (+-3.104)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        492.207 (+-74.706)       |          499.129 (+-3.551)         

Times are in microseconds (us).

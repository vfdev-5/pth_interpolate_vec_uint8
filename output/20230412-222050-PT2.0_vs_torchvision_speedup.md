Description:
- 20230412-222050-PT2.0
Torch version: 2.0.0+cpu
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: NO AVX
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 



[---------------------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------------------]
                                                                                 |      Pillow (9.5.0)     |  torch (2.0.0+cpu) PT2.0  |     torchvision resize    |  Speed-up: PTH vs TV
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=True       |   1441.872 (+-31.634)   |    3133.999 (+-41.797)    |    2650.083 (+-18.547)    |    0.846 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=True     |   2948.083 (+-18.823)   |    7241.491 (+-28.487)    |    5062.526 (+-193.631)   |    0.699 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (1024, 1024) aa=True   |  27729.240 (+-118.639)  |   59187.996 (+-159.481)   |   86632.115 (+-208.828)   |    1.464 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=True       |    959.863 (+-3.092)    |    1959.764 (+-15.033)    |    1945.851 (+-17.779)    |    0.993 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=True     |   2996.568 (+-18.702)   |    6876.854 (+-29.206)    |    5041.044 (+-18.342)    |    0.733 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=True     |   2809.417 (+-19.196)   |    6676.665 (+-25.245)    |    4840.393 (+-23.858)    |    0.725 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=True   |   17794.827 (+-99.422)  |   33402.649 (+-121.194)   |   30894.338 (+-1091.873)  |    0.925 (+-0.000)  
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=False      |                         |    3123.706 (+-18.243)    |    6165.287 (+-24.642)    |    1.974 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=False    |                         |    7237.290 (+-26.091)    |    9618.087 (+-41.331)    |    1.329 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (1024, 1024) aa=False  |                         |   59074.332 (+-180.395)   |  120177.328 (+-2954.017)  |    2.034 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=False      |                         |     1355.573 (+-5.806)    |    1708.724 (+-17.911)    |    1.261 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=False    |                         |    6429.536 (+-28.004)    |    7396.379 (+-26.848)    |    1.150 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=False    |                         |    6199.967 (+-33.862)    |    7285.841 (+-25.835)    |    1.175 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=False  |                         |   21562.549 (+-111.605)   |   25778.662 (+-2399.403)  |    1.196 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=True        |    1442.826 (+-3.937)   |    5051.518 (+-20.701)    |    4728.632 (+-19.484)    |    0.936 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=True      |   2950.145 (+-18.128)   |    9895.382 (+-35.222)    |    8076.809 (+-23.960)    |    0.816 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (1024, 1024) aa=True    |  27734.895 (+-120.465)  |   99032.332 (+-182.978)   |   87661.256 (+-233.591)   |    0.885 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=True        |    958.957 (+-6.354)    |    2231.181 (+-17.082)    |    2241.562 (+-20.083)    |    1.005 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=True      |   2992.891 (+-20.158)   |    8683.729 (+-30.855)    |    7221.833 (+-49.896)    |    0.832 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=True      |   2823.888 (+-57.261)   |    8486.350 (+-30.461)    |    6993.682 (+-23.502)    |    0.824 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=True    |  17877.953 (+-100.248)  |   37954.479 (+-181.297)   |   35374.774 (+-216.727)   |    0.932 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=False       |                         |    5043.179 (+-17.658)    |    5007.617 (+-18.053)    |    0.993 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=False     |                         |    9891.439 (+-31.783)    |    7301.735 (+-21.052)    |    0.738 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (1024, 1024) aa=False   |                         |   98928.769 (+-203.887)   |   96727.184 (+-1851.547)  |    0.978 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=False       |                         |     1490.242 (+-5.917)    |     800.316 (+-8.328)     |    0.537 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=False     |                         |    8224.615 (+-25.164)    |    5364.108 (+-18.070)    |    0.652 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=False     |                         |    8005.172 (+-24.583)    |    5328.746 (+-15.021)    |    0.666 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=False   |                         |    23815.525 (+-93.504)   |   11805.628 (+-159.437)   |    0.496 (+-0.000)  

Times are in microseconds (us).

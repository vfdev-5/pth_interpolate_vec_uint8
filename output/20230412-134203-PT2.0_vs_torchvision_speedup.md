Description:
- 20230412-134203-PT2.0
Torch version: 2.0.0+cpu
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: NO AVX
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 



[--------------------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------------------]
                                                                                 |      Pillow (9.5.0)     |  torch (2.0.0+cpu) PT2.0  |    torchvision resize    |  Speed-up: PTH vs TV
1 threads: -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=True       |    1162.659 (+-9.277)   |    2521.496 (+-19.013)    |   2204.474 (+-23.472)    |    0.874 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=True     |   2381.221 (+-16.570)   |    5845.022 (+-82.954)    |   4194.588 (+-33.179)    |    0.718 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (1024, 1024) aa=True   |  22443.577 (+-147.357)  |   47697.633 (+-299.258)   |  73080.779 (+-332.071)   |    1.532 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=True       |    771.892 (+-3.193)    |    1581.846 (+-15.787)    |   1616.360 (+-18.834)    |    1.022 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=True     |   2416.589 (+-42.885)   |    5536.582 (+-35.725)    |   4220.128 (+-32.747)    |    0.762 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=True     |   2268.977 (+-24.074)   |    5377.582 (+-35.796)    |   4028.528 (+-26.684)    |    0.749 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=True   |   14552.534 (+-63.907)  |   26995.708 (+-157.719)   |  26244.053 (+-505.652)   |    0.972 (+-0.000)  
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=False      |                         |    2518.830 (+-26.949)    |   5047.908 (+-36.319)    |    2.004 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=False    |                         |    5835.826 (+-37.958)    |   7991.453 (+-39.369)    |    1.369 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (1024, 1024) aa=False  |                         |   47617.245 (+-222.802)   |  99347.405 (+-9938.670)  |    2.086 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=False      |                         |     1093.910 (+-5.958)    |   1462.177 (+-17.812)    |    1.337 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=False    |                         |    5216.105 (+-23.758)    |   6179.793 (+-27.608)    |    1.185 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=False    |                         |    5031.895 (+-20.022)    |   6053.712 (+-30.991)    |    1.203 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=False  |                         |    17456.630 (+-97.065)   |  21857.553 (+-1854.403)  |    1.252 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=True        |    1160.227 (+-3.609)   |    4082.689 (+-22.202)    |   3861.223 (+-21.499)    |    0.946 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=True      |   2384.119 (+-14.900)   |    7999.037 (+-22.943)    |   6643.047 (+-23.467)    |    0.830 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (1024, 1024) aa=True    |   22409.429 (+-96.580)  |   79961.696 (+-171.308)   |  71110.487 (+-202.312)   |    0.889 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=True        |    772.015 (+-4.578)    |    1800.263 (+-14.872)    |   1866.762 (+-20.758)    |    1.037 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=True      |   2416.149 (+-16.251)   |    6997.100 (+-25.028)    |   5951.925 (+-19.468)    |    0.851 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=True      |   2268.443 (+-14.540)   |    6847.604 (+-35.899)    |   5765.120 (+-25.442)    |    0.842 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=True    |   14600.545 (+-38.523)  |   30667.736 (+-169.536)   |  29565.635 (+-214.455)   |    0.964 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=False       |                         |    4068.408 (+-21.312)    |   4086.201 (+-18.979)    |    1.004 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=False     |                         |    7983.073 (+-26.481)    |   5996.475 (+-13.924)    |    0.751 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (1024, 1024) aa=False   |                         |   79798.151 (+-204.083)   |  114505.879 (+-250.330)  |    1.435 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=False       |                         |     1202.207 (+-5.063)    |    674.901 (+-7.845)     |    0.561 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=False     |                         |    6639.229 (+-26.410)    |   4419.228 (+-19.705)    |    0.666 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=False     |                         |    6464.267 (+-28.937)    |   4378.899 (+-17.474)    |    0.677 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=False   |                         |    19301.811 (+-88.155)   |  10439.297 (+-128.231)   |    0.541 (+-0.000)  

Times are in microseconds (us).

Description:
- 20230413-162514-default-cpu_cap-pt2.1
Torch version: 2.1.0a0+git2b75955
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: NO AVX
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 



[------------------------------------------------------------------------------------------ Resize ------------------------------------------------------------------------------------------]
                                                                                 |  Pillow (9.0.0.post1)  |  torch (2.1.0a0+git2b75955) PT2.1  |   torchvision resize   |  Speed-up: PTH vs TV
1 threads: -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=True       |    63.259 (+-1.114)    |         637.243 (+-10.421)         |   690.594 (+-7.264)    |    1.084 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=True     |   135.149 (+-1.239)    |        1374.742 (+-13.313)         |  1317.136 (+-17.832)   |    0.958 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=True       |    53.122 (+-0.696)    |         424.303 (+-6.173)          |   440.414 (+-5.085)    |    1.038 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=True     |   141.860 (+-1.149)    |        1283.954 (+-15.948)         |  1205.254 (+-10.956)   |    0.939 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=True     |   131.587 (+-3.393)    |         1201.275 (+-9.930)         |  1137.110 (+-28.334)   |    0.947 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=True   |   694.492 (+-6.825)    |        7511.241 (+-146.808)        |  7795.599 (+-99.040)   |    1.038 (+-0.000)  
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=False      |                        |         637.632 (+-6.666)          |  1207.719 (+-22.739)   |    1.894 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=False    |                        |        1375.425 (+-26.848)         |  1868.408 (+-38.153)   |    1.358 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=False      |                        |         242.293 (+-3.056)          |   297.099 (+-4.576)    |    1.226 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=False    |                        |        1188.468 (+-11.420)         |  1433.630 (+-11.551)   |    1.206 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=False    |                        |        1152.071 (+-25.129)         |  1411.007 (+-13.630)   |    1.225 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=False  |                        |        3703.854 (+-65.833)         |  5553.051 (+-67.163)   |    1.499 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=True        |    61.768 (+-0.497)    |         997.453 (+-20.972)         |   1154.516 (+-9.984)   |    1.157 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=True      |   135.301 (+-1.266)    |        1893.632 (+-74.249)         |  1985.121 (+-27.682)   |    1.048 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=True        |    53.744 (+-0.558)    |         456.277 (+-5.279)          |   476.782 (+-5.148)    |    1.045 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=True      |   141.442 (+-1.051)    |        1637.814 (+-26.349)         |  1668.514 (+-23.441)   |    1.019 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=True      |   131.058 (+-0.986)    |        1556.274 (+-29.978)         |  1604.038 (+-25.451)   |    1.031 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=True    |   714.685 (+-7.673)    |        8029.235 (+-78.659)         |  8622.835 (+-124.554)  |    1.074 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=False       |                        |         995.165 (+-9.018)          |   1022.927 (+-8.718)   |    1.028 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=False     |                        |        1890.617 (+-26.511)         |  1530.491 (+-24.400)   |    0.810 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=False       |                        |         273.640 (+-2.712)          |   184.123 (+-2.359)    |    0.673 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=False     |                        |        1548.772 (+-44.881)         |  1129.057 (+-11.475)   |    0.729 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=False     |                        |        1508.121 (+-22.631)         |   1118.226 (+-9.445)   |    0.741 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=False   |                        |        4179.316 (+-49.671)         |  3012.297 (+-51.457)   |    0.721 (+-0.000)  

Times are in microseconds (us).

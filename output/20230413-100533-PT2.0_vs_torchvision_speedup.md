Description:
- 20230413-100533-PT2.0
Torch version: 2.0.0+cpu
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: NO AVX
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 



[--------------------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------------------]
                                                                                 |      Pillow (9.5.0)     |  torch (2.0.0+cpu) PT2.0  |    torchvision resize    |  Speed-up: PTH vs TV
1 threads: -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=True       |    1436.075 (+-6.280)   |    3151.910 (+-24.741)    |   4688.737 (+-35.597)    |    1.488 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=True     |   2950.526 (+-20.434)   |    7266.164 (+-28.356)    |   7948.703 (+-77.560)    |    1.094 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=True       |    957.229 (+-4.152)    |    1973.032 (+-20.967)    |   2130.992 (+-19.875)    |    1.080 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=True     |   2994.220 (+-21.532)   |    6894.122 (+-42.373)    |   7057.545 (+-38.806)    |    1.024 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=True     |   2803.826 (+-23.697)   |    6688.503 (+-43.002)    |   6851.118 (+-35.586)    |    1.024 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=True   |  17930.750 (+-158.646)  |   33458.326 (+-204.824)   |  33744.952 (+-5812.943)  |    1.009 (+-0.000)  
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=False      |                         |    3138.330 (+-26.213)    |   8178.735 (+-40.076)    |    2.606 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=False    |                         |    7254.269 (+-32.447)    |   12503.833 (+-63.279)   |    1.724 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=False      |                         |     1365.775 (+-5.829)    |   1878.564 (+-23.301)    |    1.375 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=False    |                         |    6440.069 (+-33.179)    |   9432.776 (+-49.253)    |    1.465 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=False    |                         |    6217.160 (+-35.983)    |   9305.477 (+-46.104)    |    1.497 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=False  |                         |   21623.857 (+-145.938)   |  28329.188 (+-1290.288)  |    1.310 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=True        |    1437.819 (+-4.783)   |    5271.796 (+-34.490)    |   6791.724 (+-32.413)    |    1.288 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=True      |   2952.816 (+-21.517)   |    10210.752 (+-58.947)   |   11016.906 (+-43.166)   |    1.079 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=True        |    956.793 (+-4.347)    |    2252.003 (+-21.105)    |   2421.985 (+-20.903)    |    1.075 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=True      |   2993.040 (+-25.153)   |    8852.263 (+-32.597)    |   9244.390 (+-44.435)    |    1.044 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=True      |   2803.835 (+-26.469)   |    8656.983 (+-38.008)    |   9026.343 (+-43.841)    |    1.043 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=True    |  17984.565 (+-162.995)  |   37920.598 (+-261.030)   |  37930.408 (+-348.332)   |    1.000 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=False       |                         |    5236.299 (+-29.053)    |   7008.583 (+-31.664)    |    1.338 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=False     |                         |    10159.084 (+-51.936)   |   10190.819 (+-39.036)   |    1.003 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=False       |                         |    1516.840 (+-17.513)    |    967.104 (+-8.784)     |    0.638 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=False     |                         |    8409.836 (+-35.272)    |   7376.530 (+-43.325)    |    0.877 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=False     |                         |    8203.791 (+-40.240)    |   7347.508 (+-33.443)    |    0.896 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=False   |                         |   24097.730 (+-222.318)   |  14288.680 (+-132.777)   |    0.593 (+-0.000)  

Times are in microseconds (us).

Description:
- 20230315-161003-pr
Torch version: 2.1.0a0+git0968a5d
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 


- 20230315-134541-nightly
Torch version: 2.1.0a0+git5309c44
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 



[---------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------]
                                                                 |  Pillow (9.0.0.post1)  |  torch (2.1.0a0+git0968a5d) PR  |  torch (2.1.0a0+git5309c44) nightly
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |    39.018 (+-0.741)    |         56.639 (+-0.688)        |          133.179 (+-1.910)         
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         36.852 (+-0.242)        |          112.771 (+-3.084)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |   128.100 (+-1.205)    |        152.491 (+-1.016)        |          305.390 (+-2.033)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        141.122 (+-1.249)        |          288.733 (+-3.516)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |   179.574 (+-1.489)    |        208.752 (+-3.570)        |          442.499 (+-7.292)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        206.377 (+-1.920)        |          436.926 (+-3.682)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |   113.309 (+-1.365)    |        132.119 (+-0.976)        |          464.843 (+-9.266)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         57.153 (+-1.154)        |          365.500 (+-2.344)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |   281.706 (+-2.380)    |        327.359 (+-2.021)        |          722.430 (+-3.482)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        230.250 (+-1.707)        |          593.532 (+-3.278)         
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |   186.926 (+-1.508)    |        210.530 (+-1.524)        |          833.762 (+-25.042)        
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         75.578 (+-0.384)        |          651.364 (+-2.819)         
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |   410.251 (+-2.663)    |        450.945 (+-3.326)        |         1128.428 (+-41.990)        
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        298.673 (+-1.821)        |          917.630 (+-4.425)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |                        |         51.937 (+-0.729)        |           54.702 (+-0.458)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         35.267 (+-0.187)        |           34.284 (+-0.297)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |                        |        144.444 (+-1.987)        |          139.654 (+-1.550)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        131.150 (+-0.922)        |          125.113 (+-1.363)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |                        |        195.818 (+-1.386)        |          185.140 (+-1.608)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        193.129 (+-1.089)        |          183.079 (+-1.690)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |                        |        124.417 (+-1.151)        |          134.977 (+-1.632)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         56.563 (+-0.295)        |           54.685 (+-0.219)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |                        |        285.209 (+-2.073)        |          325.705 (+-2.149)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        213.006 (+-1.435)        |          199.851 (+-1.425)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |                        |        192.368 (+-2.478)        |          210.964 (+-1.853)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         73.897 (+-0.207)        |           71.648 (+-1.335)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |                        |        422.955 (+-2.609)        |          464.029 (+-2.869)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        273.497 (+-1.930)        |          254.499 (+-1.979)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |    38.949 (+-0.360)    |        129.316 (+-1.082)        |          132.830 (+-1.350)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |        112.555 (+-1.180)        |          112.491 (+-1.183)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |   128.127 (+-1.294)    |        295.897 (+-1.861)        |          330.672 (+-5.759)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        283.760 (+-1.675)        |          312.518 (+-5.411)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |   179.003 (+-3.540)    |        428.809 (+-2.829)        |          473.008 (+-9.453)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        425.761 (+-3.370)        |          494.680 (+-9.075)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |   113.387 (+-1.032)    |        434.279 (+-2.296)        |          445.995 (+-3.952)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        366.346 (+-1.958)        |          365.323 (+-1.873)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |   281.409 (+-1.865)    |        669.354 (+-2.336)        |          748.466 (+-6.391)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        598.671 (+-3.548)        |          613.963 (+-8.466)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |   186.449 (+-1.578)    |        780.482 (+-10.068)       |          804.528 (+-19.030)        
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        653.348 (+-3.395)        |          788.445 (+-45.383)        
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |   410.914 (+-3.101)    |       1246.382 (+-101.843)      |         1155.497 (+-51.192)        
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        926.085 (+-5.736)        |          943.932 (+-7.854)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |                        |         70.656 (+-0.276)        |           74.449 (+-0.583)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |         53.848 (+-0.233)        |           53.316 (+-0.443)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |                        |        251.071 (+-1.609)        |          258.319 (+-3.614)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        238.187 (+-1.872)        |          250.179 (+-5.881)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |                        |        398.135 (+-2.249)        |          418.786 (+-7.906)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        394.836 (+-2.478)        |          421.216 (+-8.962)         
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |                        |        193.845 (+-1.013)        |          203.927 (+-7.220)         
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        124.757 (+-0.778)        |          123.125 (+-0.948)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |                        |        441.936 (+-2.096)        |          498.551 (+-4.656)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        369.701 (+-3.230)        |          367.818 (+-5.192)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |                        |        321.851 (+-4.140)        |          384.766 (+-17.500)        
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |       200.803 (+-107.464)       |          198.702 (+-5.339)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |                        |        686.683 (+-5.951)        |          905.370 (+-5.438)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        771.705 (+-4.404)        |          690.901 (+-5.525)         

Times are in microseconds (us).

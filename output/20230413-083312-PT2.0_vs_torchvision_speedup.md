Description:
- 20230413-083312-PT2.0
Torch version: 2.0.0+cpu
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: NO AVX
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 



[---------------------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------------------]
                                                                                 |      Pillow (9.5.0)     |  torch (2.0.0+cpu) PT2.0  |     torchvision resize    |  Speed-up: PTH vs TV
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=True       |    1441.650 (+-7.793)   |    3133.112 (+-19.848)    |    2658.643 (+-22.010)    |    0.849 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=True     |   2945.307 (+-27.857)   |    7234.375 (+-37.813)    |    5048.484 (+-166.233)   |    0.698 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (1024, 1024) aa=True   |  27771.867 (+-244.659)  |   59112.784 (+-380.406)   |   85453.461 (+-191.911)   |    1.446 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=True       |    959.119 (+-5.230)    |    1961.959 (+-15.160)    |    1946.299 (+-17.000)    |    0.992 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=True     |   2992.920 (+-16.803)   |    6870.023 (+-25.454)    |    5045.447 (+-19.603)    |    0.734 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=True     |   2805.420 (+-14.460)   |    6675.696 (+-19.798)    |    4842.727 (+-20.864)    |    0.725 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=True   |   17809.711 (+-99.375)  |   33419.405 (+-119.643)   |   30904.472 (+-7709.134)  |    0.925 (+-0.000)  
      3 torch.uint8 channels_first bilinear (64, 64) -> (224, 224) aa=False      |                         |    3126.211 (+-21.191)    |    6148.521 (+-20.971)    |    1.967 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (270, 268) aa=False    |                         |    7234.122 (+-25.336)    |    9623.514 (+-24.003)    |    1.330 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (1024, 1024) aa=False  |                         |   59102.144 (+-168.034)   |  119818.449 (+-4686.629)  |    2.027 (+-0.000)  
      3 torch.uint8 channels_first bilinear (224, 224) -> (64, 64) aa=False      |                         |     1356.032 (+-4.773)    |    1712.139 (+-11.092)    |    1.263 (+-0.000)  
      3 torch.uint8 channels_first bilinear (270, 268) -> (224, 224) aa=False    |                         |    6427.439 (+-25.443)    |    7400.255 (+-22.011)    |    1.151 (+-0.000)  
      3 torch.uint8 channels_first bilinear (256, 256) -> (224, 224) aa=False    |                         |    6202.273 (+-24.032)    |    7285.175 (+-22.074)    |    1.175 (+-0.000)  
      3 torch.uint8 channels_first bilinear (1024, 1024) -> (256, 256) aa=False  |                         |    21569.624 (+-87.971)   |   25735.221 (+-1915.450)  |    1.193 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=True        |    1440.204 (+-3.152)   |    5048.634 (+-19.188)    |    4730.987 (+-17.437)    |    0.937 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=True      |   2959.496 (+-15.789)   |    9899.122 (+-25.893)    |    8065.141 (+-32.074)    |    0.815 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (1024, 1024) aa=True    |  27739.778 (+-135.324)  |   98951.890 (+-207.316)   |   129421.902 (+-292.965)  |    1.308 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=True        |    958.800 (+-2.536)    |    2232.145 (+-14.823)    |    2234.152 (+-20.739)    |    1.001 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=True      |   2994.136 (+-17.790)   |    8666.108 (+-29.444)    |    7199.160 (+-21.471)    |    0.831 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=True      |   2806.804 (+-16.336)   |    8484.599 (+-24.164)    |    6975.706 (+-24.476)    |    0.822 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=True    |   17748.965 (+-93.011)  |   37918.864 (+-213.322)   |   35278.220 (+-244.379)   |    0.930 (+-0.000)  
      3 torch.uint8 channels_last bilinear (64, 64) -> (224, 224) aa=False       |                         |    5041.425 (+-19.732)    |    5009.649 (+-18.735)    |    0.994 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (270, 268) aa=False     |                         |    9902.715 (+-30.552)    |    7311.017 (+-20.245)    |    0.738 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (1024, 1024) aa=False   |                         |   98949.853 (+-199.764)   |   137463.340 (+-256.288)  |    1.389 (+-0.000)  
      3 torch.uint8 channels_last bilinear (224, 224) -> (64, 64) aa=False       |                         |     1488.239 (+-4.232)    |     797.002 (+-5.500)     |    0.536 (+-0.000)  
      3 torch.uint8 channels_last bilinear (270, 268) -> (224, 224) aa=False     |                         |    8218.452 (+-25.542)    |    5357.390 (+-19.943)    |    0.652 (+-0.000)  
      3 torch.uint8 channels_last bilinear (256, 256) -> (224, 224) aa=False     |                         |    8001.817 (+-23.861)    |    5326.541 (+-17.561)    |    0.666 (+-0.000)  
      3 torch.uint8 channels_last bilinear (1024, 1024) -> (256, 256) aa=False   |                         |   23820.776 (+-122.727)   |   11831.602 (+-148.078)   |    0.497 (+-0.000)  

Times are in microseconds (us).

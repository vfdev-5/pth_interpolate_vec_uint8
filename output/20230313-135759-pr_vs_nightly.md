Description:
- 20230313-133243-pr
Torch version: 2.1.0a0+git1d3a939
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 


- 20230313-134520-nightly
Torch version: 2.1.0a0+git5309c44
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 



[---------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------]
                                                                 |  Pillow (9.0.0.post1)  |  torch (2.1.0a0+git1d3a939) PR  |  torch (2.1.0a0+git5309c44) nightly
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |    38.487 (+-0.306)    |         56.346 (+-0.339)        |          132.536 (+-1.491)         
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         36.192 (+-0.202)        |          110.609 (+-0.746)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |   127.026 (+-1.062)    |        149.924 (+-0.958)        |          292.207 (+-2.027)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        134.171 (+-1.156)        |          276.796 (+-1.953)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |   178.084 (+-1.084)    |        200.281 (+-1.439)        |          416.424 (+-3.683)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        198.008 (+-1.316)        |          414.386 (+-1.848)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |   112.948 (+-1.115)    |        129.274 (+-1.597)        |          441.302 (+-2.747)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         54.919 (+-0.343)        |          364.247 (+-3.346)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |   282.665 (+-2.485)    |        324.791 (+-2.644)        |          691.615 (+-4.512)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        211.900 (+-1.656)        |          583.074 (+-12.854)        
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |   185.903 (+-1.773)    |        201.141 (+-2.824)        |          783.053 (+-4.576)         
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         72.116 (+-0.261)        |          649.771 (+-4.198)         
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |   408.651 (+-2.172)    |        436.709 (+-2.922)        |         1100.548 (+-11.212)        
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        268.812 (+-1.700)        |          906.638 (+-2.984)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |                        |         53.462 (+-0.215)        |           54.386 (+-0.221)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         34.831 (+-0.198)        |           33.479 (+-0.176)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |                        |        142.814 (+-1.391)        |          140.232 (+-1.119)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        127.492 (+-0.808)        |          125.583 (+-1.206)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |                        |        190.848 (+-1.475)        |          185.176 (+-1.279)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        188.934 (+-1.353)        |          183.222 (+-1.245)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |                        |        124.561 (+-1.190)        |          132.561 (+-1.274)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         55.886 (+-0.196)        |           54.603 (+-0.258)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |                        |        289.728 (+-7.670)        |          307.923 (+-2.517)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        200.142 (+-1.347)        |          200.009 (+-1.370)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |                        |        193.792 (+-2.324)        |          207.900 (+-2.445)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         72.862 (+-0.275)        |           71.540 (+-0.259)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |                        |        422.480 (+-2.226)        |          451.936 (+-2.840)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        253.278 (+-2.011)        |          254.801 (+-1.640)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |    38.401 (+-0.424)    |        131.042 (+-1.188)        |          132.604 (+-0.965)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |        112.636 (+-1.077)        |          111.033 (+-0.882)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |   127.785 (+-1.094)    |        295.334 (+-1.636)        |          317.431 (+-4.656)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        280.238 (+-1.432)        |          310.711 (+-4.103)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |   178.609 (+-1.473)    |        422.858 (+-1.670)        |          461.125 (+-7.713)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        420.145 (+-2.587)        |          474.333 (+-8.597)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |   113.253 (+-2.725)    |        433.167 (+-2.521)        |          442.099 (+-3.117)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        364.731 (+-3.225)        |          363.988 (+-2.167)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |   282.530 (+-2.376)    |        674.080 (+-2.417)        |          724.077 (+-4.803)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        584.824 (+-4.092)        |          619.099 (+-4.879)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |   185.718 (+-1.689)    |        771.039 (+-4.169)        |          787.789 (+-5.200)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        652.631 (+-72.811)       |          647.919 (+-3.986)         
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |   408.338 (+-2.459)    |       1076.518 (+-10.833)       |         1132.723 (+-11.433)        
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        905.883 (+-5.080)        |          937.306 (+-4.873)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |                        |         72.901 (+-0.312)        |           73.960 (+-0.207)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |         54.081 (+-0.598)        |           53.132 (+-0.290)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |                        |        250.762 (+-1.430)        |          276.411 (+-7.745)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        235.713 (+-5.739)        |          266.253 (+-3.807)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |                        |        393.303 (+-1.772)        |          451.076 (+-5.440)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        389.991 (+-2.960)        |          441.376 (+-10.967)        
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |                        |        193.009 (+-1.391)        |          201.109 (+-1.703)         
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        124.009 (+-0.701)        |          123.209 (+-1.041)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |                        |        446.291 (+-2.011)        |          481.717 (+-5.655)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        356.233 (+-1.761)        |          392.546 (+-3.717)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |                        |        321.468 (+-1.969)        |          333.681 (+-1.986)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        198.823 (+-1.217)        |          197.557 (+-1.263)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |                        |        637.630 (+-2.821)        |          692.533 (+-3.104)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        466.476 (+-2.782)        |          499.129 (+-3.551)         

Times are in microseconds (us).

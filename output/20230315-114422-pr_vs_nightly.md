Description:
- 20230315-113129-pr
Torch version: 2.1.0a0+gitcc42a3f
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 


- 20230313-134520-nightly
Torch version: 2.1.0a0+git5309c44
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 



[---------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------]
                                                                 |  Pillow (9.0.0.post1)  |  torch (2.1.0a0+gitcc42a3f) PR  |  torch (2.1.0a0+git5309c44) nightly
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |    38.481 (+-0.472)    |         56.689 (+-0.459)        |          132.536 (+-1.491)         
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         38.475 (+-0.300)        |          110.609 (+-0.746)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |   127.101 (+-1.094)    |        158.947 (+-1.537)        |          292.207 (+-2.027)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        147.393 (+-1.146)        |          276.796 (+-1.953)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |   178.276 (+-1.349)    |        216.679 (+-1.381)        |          416.424 (+-3.683)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        214.049 (+-1.439)        |          414.386 (+-1.848)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |   113.219 (+-1.126)    |        131.612 (+-1.790)        |          441.302 (+-2.747)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         57.917 (+-0.196)        |          364.247 (+-3.346)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |   282.170 (+-2.885)    |        326.370 (+-1.914)        |          691.615 (+-4.512)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        239.923 (+-1.777)        |          583.074 (+-12.854)        
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |   186.865 (+-1.657)    |        204.513 (+-1.912)        |          783.053 (+-4.576)         
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         75.964 (+-0.204)        |          649.771 (+-4.198)         
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |   409.986 (+-2.516)    |        445.361 (+-6.145)        |         1100.548 (+-11.212)        
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        310.091 (+-1.524)        |          906.638 (+-2.984)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |                        |         53.623 (+-0.386)        |           54.386 (+-0.221)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         36.194 (+-0.909)        |           33.479 (+-0.176)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |                        |        149.318 (+-1.350)        |          140.232 (+-1.119)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        135.592 (+-1.144)        |          125.583 (+-1.206)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |                        |        200.943 (+-1.635)        |          185.176 (+-1.279)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        199.068 (+-1.499)        |          183.222 (+-1.245)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |                        |        126.887 (+-1.774)        |          132.561 (+-1.274)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         57.621 (+-0.242)        |           54.603 (+-0.258)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |                        |        290.889 (+-2.251)        |          307.923 (+-2.517)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        217.638 (+-1.731)        |          200.009 (+-1.370)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |                        |        196.915 (+-1.748)        |          207.900 (+-2.445)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         75.191 (+-0.216)        |           71.540 (+-0.259)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |                        |        426.161 (+-2.633)        |          451.936 (+-2.840)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        277.570 (+-2.353)        |          254.801 (+-1.640)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |    38.631 (+-0.189)    |        130.969 (+-1.039)        |          132.604 (+-0.965)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |        113.673 (+-0.798)        |          111.033 (+-0.882)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |   127.412 (+-0.987)    |        303.405 (+-2.377)        |          317.431 (+-4.656)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        289.503 (+-2.266)        |          310.711 (+-4.103)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |   177.833 (+-1.345)    |        440.319 (+-5.497)        |          461.125 (+-7.713)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        433.892 (+-5.701)        |          474.333 (+-8.597)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |   113.762 (+-2.657)    |        436.299 (+-3.468)        |          442.099 (+-3.117)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        367.868 (+-2.785)        |          363.988 (+-2.167)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |   281.670 (+-1.953)    |        675.667 (+-3.868)        |          724.077 (+-4.803)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        604.856 (+-4.670)        |          619.099 (+-4.879)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |   186.726 (+-1.397)    |        851.744 (+-16.172)       |          787.789 (+-5.200)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        653.602 (+-16.004)       |          647.919 (+-3.986)         
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |   408.864 (+-2.370)    |       1086.162 (+-38.289)       |         1132.723 (+-11.433)        
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        930.350 (+-4.975)        |          937.306 (+-4.873)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |                        |         72.274 (+-0.239)        |           73.960 (+-0.207)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |         54.973 (+-0.279)        |           53.132 (+-0.290)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |                        |        264.747 (+-3.207)        |          276.411 (+-7.745)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        255.906 (+-3.055)        |          266.253 (+-3.807)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |                        |        422.476 (+-7.144)        |          451.076 (+-5.440)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        416.894 (+-4.632)        |          441.376 (+-10.967)        
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |                        |        195.922 (+-1.265)        |          201.109 (+-1.703)         
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        126.044 (+-0.840)        |          123.209 (+-1.041)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |                        |        454.928 (+-4.295)        |          481.717 (+-5.655)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        382.231 (+-3.588)        |          392.546 (+-3.717)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |                        |        355.149 (+-20.139)       |          333.681 (+-1.986)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        294.683 (+-24.061)       |          197.557 (+-1.263)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |                        |        762.678 (+-25.721)       |          692.533 (+-3.104)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        731.566 (+-40.557)       |          499.129 (+-3.551)         

Times are in microseconds (us).

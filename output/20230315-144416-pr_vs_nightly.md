Description:
- 20230315-135753-pr
Torch version: 2.1.0a0+gitcc42a3f
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 


- 20230315-134541-nightly
Torch version: 2.1.0a0+git5309c44
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 



[---------------------------------------------------------------------------- Resize ---------------------------------------------------------------------------]
                                                                 |  Pillow (9.0.0.post1)  |  torch (2.1.0a0+gitcc42a3f) PR  |  torch (2.1.0a0+git5309c44) nightly
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |    38.786 (+-0.881)    |         56.004 (+-0.482)        |          133.179 (+-1.910)         
      3 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         37.486 (+-0.404)        |          112.771 (+-3.084)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |   128.681 (+-1.290)    |        157.046 (+-1.502)        |          305.390 (+-2.033)         
      3 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        146.393 (+-1.331)        |          288.733 (+-3.516)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |   179.376 (+-1.679)    |        215.810 (+-1.805)        |          442.499 (+-7.292)         
      3 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        212.509 (+-1.878)        |          436.926 (+-3.682)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |   113.290 (+-1.451)    |        127.865 (+-1.446)        |          464.843 (+-9.266)         
      3 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         56.838 (+-0.271)        |          365.500 (+-2.344)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |   281.687 (+-2.075)    |        325.237 (+-2.703)        |          722.430 (+-3.482)         
      3 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        239.070 (+-2.288)        |          593.532 (+-3.278)         
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |   186.229 (+-1.689)    |        200.704 (+-2.258)        |          833.762 (+-25.042)        
      3 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         75.184 (+-0.245)        |          651.364 (+-2.819)         
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |   410.003 (+-2.568)    |        444.491 (+-10.405)       |         1128.428 (+-41.990)        
      3 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        309.276 (+-2.466)        |          917.630 (+-4.425)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=True     |                        |         52.412 (+-0.241)        |           54.702 (+-0.458)         
      4 torch.uint8 channels_last bilinear 256 -> 32 aa=False    |                        |         34.967 (+-0.262)        |           34.284 (+-0.297)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=True    |                        |        147.081 (+-1.393)        |          139.654 (+-1.550)         
      4 torch.uint8 channels_last bilinear 256 -> 224 aa=False   |                        |        133.678 (+-1.486)        |          125.113 (+-1.363)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=True    |                        |        200.139 (+-1.446)        |          185.140 (+-1.608)         
      4 torch.uint8 channels_last bilinear 256 -> 320 aa=False   |                        |        197.580 (+-1.524)        |          183.079 (+-1.690)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=True     |                        |        124.506 (+-1.495)        |          134.977 (+-1.632)         
      4 torch.uint8 channels_last bilinear 520 -> 32 aa=False    |                        |         56.421 (+-0.261)        |           54.685 (+-0.219)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=True    |                        |        289.083 (+-1.706)        |          325.705 (+-2.149)         
      4 torch.uint8 channels_last bilinear 520 -> 224 aa=False   |                        |        216.116 (+-1.682)        |          199.851 (+-1.425)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=True     |                        |        194.591 (+-2.292)        |          210.964 (+-1.853)         
      4 torch.uint8 channels_last bilinear 712 -> 32 aa=False    |                        |         73.954 (+-0.358)        |           71.648 (+-1.335)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=True    |                        |        426.140 (+-1.799)        |          464.029 (+-2.869)         
      4 torch.uint8 channels_last bilinear 712 -> 224 aa=False   |                        |        276.233 (+-1.902)        |          254.499 (+-1.979)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |    38.967 (+-0.279)    |        129.916 (+-1.319)        |          132.830 (+-1.350)         
      3 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |        112.659 (+-1.042)        |          112.491 (+-1.183)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |   128.631 (+-1.311)    |        300.425 (+-2.137)        |          330.672 (+-5.759)         
      3 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        288.331 (+-4.910)        |          312.518 (+-5.411)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |   179.562 (+-1.577)    |        436.546 (+-7.915)        |          473.008 (+-9.453)         
      3 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        432.695 (+-4.601)        |          494.680 (+-9.075)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |   113.496 (+-1.304)    |        437.038 (+-2.254)        |          445.995 (+-3.952)         
      3 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        367.518 (+-2.434)        |          365.323 (+-1.873)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |   281.880 (+-1.827)    |        676.209 (+-4.031)        |          748.466 (+-6.391)         
      3 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        603.441 (+-13.712)       |          613.963 (+-8.466)         
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |   186.440 (+-1.632)    |        774.514 (+-4.060)        |          804.528 (+-19.030)        
      3 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        803.250 (+-45.150)       |          788.445 (+-45.383)        
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |   412.164 (+-2.801)    |       1089.326 (+-126.596)      |         1155.497 (+-51.192)        
      3 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        934.856 (+-72.046)       |          943.932 (+-7.854)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=True    |                        |         71.708 (+-0.356)        |           74.449 (+-0.583)         
      4 torch.uint8 channels_first bilinear 256 -> 32 aa=False   |                        |         54.291 (+-0.298)        |           53.316 (+-0.443)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=True   |                        |        285.875 (+-2.366)        |          258.319 (+-3.614)         
      4 torch.uint8 channels_first bilinear 256 -> 224 aa=False  |                        |        273.218 (+-2.088)        |          250.179 (+-5.881)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=True   |                        |        459.332 (+-4.089)        |          418.786 (+-7.906)         
      4 torch.uint8 channels_first bilinear 256 -> 320 aa=False  |                        |        458.771 (+-5.694)        |          421.216 (+-8.962)         
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=True    |                        |        192.997 (+-1.238)        |          203.927 (+-7.220)         
      4 torch.uint8 channels_first bilinear 520 -> 32 aa=False   |                        |        125.736 (+-0.825)        |          123.125 (+-0.948)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=True   |                        |        477.576 (+-2.082)        |          498.551 (+-4.656)         
      4 torch.uint8 channels_first bilinear 520 -> 224 aa=False  |                        |        404.541 (+-2.494)        |          367.818 (+-5.192)         
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=True    |                        |        473.119 (+-14.648)       |          384.766 (+-17.500)        
      4 torch.uint8 channels_first bilinear 712 -> 32 aa=False   |                        |        200.963 (+-42.727)       |          198.702 (+-5.339)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=True   |                        |        944.857 (+-90.971)       |          905.370 (+-5.438)         
      4 torch.uint8 channels_first bilinear 712 -> 224 aa=False  |                        |        534.118 (+-3.297)        |          690.901 (+-5.525)         

Times are in microseconds (us).
